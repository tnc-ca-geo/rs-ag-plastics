{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining threshold\n",
    "Testing all of the possible threshold values between 0 and 1.0 for hoop and mulch based on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "# Santa Maria\n",
    "sm_csv = 'N:/OCEANS_Program/Plastics/Agricultural_Plastics/AgPlastics_Pro/thresholding/SantaMaria_val_o_withPlasticProbs_p95.csv'\n",
    "sm = pd.read_csv(sm_csv)\n",
    "\n",
    "wv_csv = 'N:/OCEANS_Program/Plastics/Agricultural_Plastics/AgPlastics_Pro/thresholding/Watsonville_Points_BM_withPlasticProbs_p95_WY2022.csv'\n",
    "wv = pd.read_csv(wv_csv)\n",
    "\n",
    "ox_csv = 'N:/OCEANS_Program/Plastics/Agricultural_Plastics/AgPlastics_Pro/thresholding/Oxnard_Points_withPlasticProbs_p95_WY2022.csv'\n",
    "ox = pd.read_csv(ox_csv)\n",
    "# Convert 'blackmulch' to 'mulch' in the 'Type' column\n",
    "ox['Type'] = ox['Type'].replace('blackmulch', 'mulch')\n",
    "\n",
    "# print(\"Unique values in 'Type' column for Santa Maria dataset:\", sm['Type'].unique())\n",
    "# print(\"Unique values in 'Type' column for Watsonville dataset:\", wv['Type'].unique())\n",
    "# print(\"Unique values in 'Type' column for Oxnard dataset:\", ox['Type'].unique())\n",
    "\n",
    "# Define which dataset to use\n",
    "data = ox\n",
    "\n",
    "data = pd.concat([ox, wv, sm], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing mulch and hoop confusion\n",
    "\n",
    "If we take points that are classified as both mulch and hoop based on whatever thresholds we design, \n",
    "it will work most of the time. When a point is classified higher as mulch, it is mulch. \n",
    "There is some confusion:\n",
    "\n",
    "- In Santa Maria, before thresholding, this approach would misclassify hoop as mulch 1.3% of the time, and misclassify mulch as hoop 7.4% of the time\n",
    "- In Watsonville, before thresholding, this approach misclassifies hoop as mulch 0.6% of the time, and misclassifies mulch as hoop 0 times\n",
    "- In Oxnard, no confusion\n",
    "- Overall, 1% of hoop points would be misclassified as mulch and 2% of mulch points would be misclassified as hoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the points that are classified as \"hoop\"\n",
      "Hoop count: 296\n",
      "Mulch count: 3\n",
      "Confusion rate: 0.010033444816053512\n",
      "Of the points that are classified as \"mulch\"\n",
      "Hoop count: 11\n",
      "Mulch count: 482\n",
      "Confusion rate: 0.02231237322515213\n"
     ]
    }
   ],
   "source": [
    "hoop = data[data['Type'] == 'hoop']\n",
    "hoop_count = hoop[hoop['hoop_p95'] > hoop['mulch_p95']].shape[0]\n",
    "mulch_count = hoop[hoop['mulch_p95'] > hoop['hoop_p95']].shape[0]\n",
    "\n",
    "if hoop_count == 0: # oxnard has no hoop points in 2022\n",
    "    print('No points classified as \"hoop\"')\n",
    "else:\n",
    "    print('Of the points that are classified as \"hoop\"')\n",
    "    print(f\"Hoop count: {hoop_count}\")\n",
    "    print(f\"Mulch count: {mulch_count}\")\n",
    "    print(f'Confusion rate: {mulch_count / (hoop_count + mulch_count)}')\n",
    "\n",
    "mulch = data[data['Type'] == 'mulch']\n",
    "hoop_count = mulch[mulch['hoop_p95'] > mulch['mulch_p95']].shape[0]\n",
    "mulch_count = mulch[mulch['mulch_p95'] > mulch['hoop_p95']].shape[0]\n",
    "\n",
    "print('Of the points that are classified as \"mulch\"')\n",
    "print(f\"Hoop count: {hoop_count}\")\n",
    "print(f\"Mulch count: {mulch_count}\")\n",
    "print(f'Confusion rate: {hoop_count / (hoop_count + mulch_count)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds: Mulch: 0.45, Hoop: 0.7000000000000001\n",
      "Highest accuracy: 0.8644747393744988\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the accuracy for given thresholds based on our rules\n",
    "def calculate_accuracy(thresholds, data):\n",
    "    mulch_threshold, hoop_threshold = thresholds\n",
    "    correct_classifications = 0\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        if row['Type'] == 'mulch' and row['mulch_p95'] >= mulch_threshold:# and (row['hoop_p95'] < hoop_threshold or row['hoop_p95'] < row['mulch_p95']):\n",
    "            correct_classifications += 1\n",
    "        elif row['Type'] == 'hoop' and row['hoop_p95'] >= hoop_threshold:# and (row['mulch_p95'] < mulch_threshold or row['mulch_p95'] < row['hoop_p95']):\n",
    "            correct_classifications += 1\n",
    "        elif row['Type'] == 'other' and row['mulch_p95'] < mulch_threshold and row['hoop_p95'] < hoop_threshold:\n",
    "            correct_classifications += 1\n",
    "    \n",
    "    return correct_classifications / len(data)\n",
    "\n",
    "# Define the range of thresholds to test\n",
    "thresholds_range = np.arange(0.0, 1.05, 0.05)\n",
    "\n",
    "# Initialize variables to store the best thresholds and highest accuracy\n",
    "best_thresholds = (0, 0)\n",
    "highest_accuracy = 0\n",
    "\n",
    "# Iterate over all possible combinations of thresholds\n",
    "for mulch_threshold in thresholds_range:\n",
    "    for hoop_threshold in thresholds_range:\n",
    "        accuracy = calculate_accuracy((mulch_threshold, hoop_threshold), data)\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            best_thresholds = (mulch_threshold, hoop_threshold)\n",
    "\n",
    "print(f\"Best thresholds: Mulch: {best_thresholds[0]}, Hoop: {best_thresholds[1]}\")\n",
    "print(f\"Highest accuracy: {highest_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resulting thresholds\n",
    "\n",
    "**With the test for hoop/mulch confusion:**\n",
    "- In Santa Maria, it's Mulch 0.5 and Hoop 0.75 (91% accurate)\n",
    "- In Watsonville, it's Mulch 0.05 and Hoop 0.05 (81% accurate)\n",
    "- In Oxnard, it's Mulch 0.45 and Hoop 0.35 (96% accurate)\n",
    "\n",
    "Overall, it's Mulch 0.45 and Hoop 0.75 (85% accurate)\n",
    "\n",
    "**Without the inter-plastic confusion test:**\n",
    "- In Santa Maria, it's Mulch 0.5 and Hoop 0.5 (93% accurate)\n",
    "- In Watsonville, it's the same - Mulch 0.05 and Hoop 0.05 (81% accurate)\n",
    "- In Oxnard, it's the same -  Mulch 0.45 and Hoop 0.35 (96% accurate)\n",
    "\n",
    "Overall, it's Mulch 0.45 and Hoop 0.70 (86% accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly something weird is going on in Watsonville with one of the classes\n",
    "Could try again with 2021? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
